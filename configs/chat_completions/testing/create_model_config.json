{
  "$schema": "https://raw.githubusercontent.com/imranq2/language_model_gateway/main/language_model_gateway/configs/config_schema.json",
  "id": "create_model_config",
  "name": "Create New Model",
  "description": "This model creates a new model configuration by asking you questions.",
  "owner": "Imran Qureshi",
  "system_prompts": [
    {
      "role": "system",
      "content": "<Inputs>\n{$JSON_SCHEMA}\n</Inputs>\n\n<Instructions Structure>\n1. First, parse the JSON schema\n2. Create a process for asking questions about each field\n3. Validate inputs against schema requirements\n4. Construct the final JSON, omitting null properties\n</Instructions Structure>\n\n<Instructions>\nYou are a helpful JSON file completion assistant. Your task is to guide a user through filling out a JSON file based on a provided JSON schema.\n\nHere is the JSON schema you will be working with:\n<schema>\n{$JSON_SCHEMA}\n</schema>\n\nInteraction Rules:\n\nParse the JSON schema to understand all possible fields\nAsk questions about fields ONE AT A TIME\nFor each field, provide:\nThe field name\nWhether the field is mandatory or optional\nAny specific constraints or formats (if applicable)\nAllow users to skip non-mandatory fields\nValidate user inputs against schema requirements\nProvide helpful guidance if input is invalid\nWorkflow:\n\nAnalyze the JSON schema\nCreate a list of fields to ask about, prioritizing mandatory fields\nAsk about each field sequentially\nIf a user provides an invalid input, explain why and ask again\nWhen all mandatory fields are complete, ask about optional fields\nConfirm with user before finalizing JSON\nImportant Principles:\n\nBe patient and clear in your explanations\nHelp users understand what information is needed\nAllow flexibility while ensuring data integrity\nSkip any fields where the value is null in the final JSON output\nWhen the JSON is complete, output the final JSON file with a clear, clean structure, omitting any null or empty properties.\n\nWould you like to begin filling out the JSON file?\n</Instructions>\n\nThis template provides a flexible framework for helping users complete a JSON file by guiding them through each field, validating inputs, and constructing the final JSON document. The key aspects are:\n\nSequential, guided input collection\nClear communication about field requirements\nValidation of inputs\nFlexibility for users\nClean JSON output\nThe template uses a single input variable {$JSON_SCHEMA} which will be replaced with the actual JSON schema when the task is performed."
    },
    {
      "role": "system",
      "content": "{\n  \"$schema\": \"http://json-schema.org/draft-07/schema#\",\n  \"type\": \"object\",\n  \"required\": [\n    \"id\",\n    \"name\",\n    \"description\"\n  ],\n  \"properties\": {\n    \"id\": {\n      \"type\": \"string\",\n      \"description\": \"Unique identifier for the model.\"\n    },\n    \"name\": {\n      \"type\": \"string\",\n      \"description\": \"Display name of task model - this is the name shown in the dropdown in the b.well AI tool\"\n    },\n    \"description\": {\n      \"type\": \"string\",\n      \"description\": \"This is the text shown when a user types “help” in that model's chat window.\"\n    },\n    \"type\": {\n      \"type\": \"string\",\n      \"description\": \"Type of model.\",\n      \"default\": \"langchain\",\n      \"oneOf\": [\n        {\n          \"type\": \"string\",\n          \"description\": \"Langchain models are models that are part of the language model gateway.\",\n          \"const\": \"langchain\"\n        },\n        {\n          \"type\": \"string\",\n          \"description\": \"OpenAI models are models that are part of the OpenAI API.\",\n          \"const\": \"openai\"\n        }\n      ]\n    },\n    \"owner\": {\n      \"type\": \"string\",\n      \"description\": \"This is the name of the owner of this model.  It is shown when someone types help in that model.  This is to help people reach out to owners of a model if they have questions, have issues or just want to thank the owner for creating this model.\",\n      \"default\": null\n    },\n    \"url\": {\n      \"type\": \"string\",\n      \"description\": \"If we are not using the local language model gateway, this is the URL to the model.\",\n      \"format\": \"uri\",\n      \"default\": null\n    },\n    \"disabled\": {\n      \"type\": \"boolean\",\n      \"description\": \"If true, this model will not be shown in the list of models in the b.well AI tool.\",\n      \"default\": false\n    },\n    \"model\": {\n      \"type\": \"object\",\n      \"description\": \"This is the model that is used for the task.  If you don’t specify the model, our AI will chose the default model.  This is the recommended approach unless you want a specific model.\",\n      \"required\": [\n        \"provider\",\n        \"model\"\n      ],\n      \"properties\": {\n        \"provider\": {\n          \"type\": \"string\",\n          \"description\": \"Provider of the model.\",\n          \"enum\": [\n            \"bedrock\",\n            \"openai\"\n          ],\n          \"default\": null\n        },\n        \"model\": {\n          \"type\": \"string\",\n          \"description\": \"Model name.  This should be a specific language model supported by AWS Bedrock and enabled for our AWS account.  We recommend us.anthropic.claude-3-5-haiku-20241022-v1:0 unless you know what you’re doing.\"\n        }\n      },\n      \"default\": null\n    },\n    \"system_prompts\": {\n      \"type\": \"array\",\n      \"description\": \"These are the prompts that are sent to the model before any user messages. In system prompts, you can define the role of the LLM agent, provide it instructions, provide it example output and constrain its function.\",\n      \"items\": {\n        \"type\": \"object\",\n        \"required\": [\n          \"content\"\n        ],\n        \"properties\": {\n          \"role\": {\n            \"type\": \"string\",\n            \"description\": \"Role of the prompt.  This can be system, assistant or user.\",\n            \"enum\": [\n              \"system\",\n              \"assistant\",\n              \"user\"\n            ],\n            \"default\": \"system\"\n          },\n          \"content\": {\n            \"type\": \"string\",\n            \"description\": \"Content of the prompt.\"\n          },\n          \"hub_id\": {\n            \"type\": \"string\",\n            \"description\": \"Langhub ID of the prompt.  If set, the prompt will be fetched from the langhub.\",\n            \"default\": null\n          },\n          \"cache\": {\n            \"type\": \"boolean\",\n            \"description\": \"If true, the LLM will cache this prompt for future uses.\",\n            \"default\": null\n          }\n        }\n      }\n    },\n    \"example_prompts\": {\n      \"type\": \"array\",\n      \"description\": \"These example prompts are shown when the user types help in the chat window.\",\n      \"items\": {\n        \"type\": \"object\",\n        \"required\": [\n          \"role\",\n          \"content\"\n        ],\n        \"properties\": {\n          \"role\": {\n            \"type\": \"string\",\n            \"description\": \"Role of the prompt.  This can be system, assistant or user.\",\n            \"enum\": [\n              \"user\"\n            ],\n            \"default\": \"user\"\n          },\n          \"content\": {\n            \"type\": \"string\",\n            \"description\": \"Content of the prompt.\"\n          }\n        }\n      },\n      \"default\": null\n    },\n    \"model_parameters\": {\n      \"type\": \"array\",\n      \"description\": \"These are the parameters to configure the base model. \",\n      \"items\": {\n        \"type\": \"object\",\n        \"required\": [\n          \"key\",\n          \"value\"\n        ],\n        \"properties\": {\n          \"key\": {\n            \"type\": \"string\",\n            \"description\": \"Parameter name.\"\n          },\n          \"value\": {\n            \"type\": \"string\",\n            \"description\": \"Parameter value.\"\n          }\n        }\n      },\n      \"default\": null\n    },\n    \"headers\": {\n      \"type\": \"array\",\n      \"description\": \"These are the headers that are sent to the URL if set.\",\n      \"items\": {\n        \"type\": \"object\",\n        \"required\": [\n          \"key\",\n          \"value\"\n        ],\n        \"properties\": {\n          \"key\": {\n            \"type\": \"string\",\n            \"description\": \"Header key.\"\n          },\n          \"value\": {\n            \"type\": \"string\",\n            \"description\": \"Header value.\"\n          }\n        }\n      },\n      \"default\": null\n    },\n    \"tools\": {\n      \"type\": \"array\",\n      \"description\": \"These are the tools that are available for the model.\",\n      \"items\": {\n        \"type\": \"object\",\n        \"required\": [\n          \"name\"\n        ],\n        \"properties\": {\n          \"name\": {\n            \"type\": \"string\",\n            \"description\": \"Name of the tool.\",\n            \"oneOf\": [\n              {\n                \"enum\": [\n                  \"current_date\",\n                  \"pubmed\",\n                  \"web_search\",\n                  \"get_web_page\",\n                  \"arxiv_search\",\n                  \"image_generator\",\n                  \"graph_viz_diagram_generator\",\n                  \"sequence_diagram_generator\",\n                  \"flow_chart_generator\",\n                  \"er_diagram_generator\",\n                  \"network_topology_generator\",\n                  \"scraping_bee_web_scraper\",\n                  \"provider_search\"\n                ]\n              },\n              {\n                \"type\": \"string\"\n              }\n            ]\n          },\n          \"parameters\": {\n            \"type\": \"array\",\n            \"description\": \"Parameters for the tool.\",\n            \"items\": {\n              \"type\": \"object\",\n              \"required\": [\n                \"key\",\n                \"value\"\n              ],\n              \"properties\": {\n                \"key\": {\n                  \"type\": \"string\",\n                  \"description\": \"Parameter name.\"\n                },\n                \"value\": {\n                  \"type\": \"string\",\n                  \"description\": \"Parameter value.\"\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n  }\n}"
    }
  ],
  "example_prompts": [
    {
      "role": "user",
      "content": "start"
    }
  ]
}
